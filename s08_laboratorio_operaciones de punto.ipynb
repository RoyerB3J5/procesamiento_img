{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HwmPYI7uF9d"
   },
   "source": [
    "**ESCUELA DE INGENIER√çA MECATR√ìNICA**\n",
    "\n",
    "## `PROCESAMIENTO DIGITAL DE SE√ëALES E IM√ÅGENES`\n",
    "\n",
    "### `Docente: Ms. Ing. Emerson Maximo Asto Rodriguez`\n",
    "\n",
    "```\n",
    "Pr√°ctica: OpenCV y Operaciones de punto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Q8ByGyiuF9i"
   },
   "source": [
    "# <font color=#FF0000>OpenCV</color>\n",
    "\n",
    "* Mas de 2500 algoritmos optimizados\n",
    "\n",
    "* C/C++, Python, Java y MATLAB, soporta Windows, Linux, Android y Mac OS\n",
    "\n",
    "* Cuda y OpenCL (Actualmente en desarrollo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcZTJnk4uF9j"
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojkzAOniuF9k"
   },
   "source": [
    "### **Leer y mostrar una imagen con OpenCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpnrAfz5uF9k"
   },
   "source": [
    "Lectura -> cv2.imread(ruta de imagen, opc*)\n",
    " * Corregir colores usando indexaci√≥n\n",
    " * Corregir colores cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
    " * opc -> cv2.IMREAD_GRAYSCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgSRC = './lab_images/robotSofia.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBPFWDsoKZ2z",
    "outputId": "1553c256-d721-487d-d3a2-3e5f029dcdf9"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgSRC) #[..., ::-1]\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# plt.figure(figsize=(15,10))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P1. Que sucede si usamos matplotlib para mostrar una im√°gen le√≠da con openCV?\n",
    "- Se van a generar errores en los colores al mostrar la misma imagen pero con la biblioteca de Matplotlib ya que esta √∫ltima espera que las im√°genes esten en un formato GGB (Rojo, Verde, Azul), en cambio OpenCV interpreta las im√°genes en un formato de BRG (Azul,Verde,Rojo), por lo cual, existe una variaci√≥n en el orden del rojo y en azul, es por ello que al mostrar con Matplotlib, sin realizar un ajuste en el c√≥digo, se mostrar√° una figura verdosa o azulado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFIkZFazuF9o"
   },
   "source": [
    "### **Consideraciones al mostrar imagenes con matplotlib**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Imagen en escala de grises*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stO2eihpuF9p",
    "outputId": "9182e421-befc-46c8-9839-07e4362a82a7"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgSRC,0)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Se realiza un autoescalado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black = np.zeros([100, 100], dtype=np.uint8)\n",
    "gray = np.ones([100, 100], dtype=np.uint8) * 128\n",
    "white = np.ones([100, 100], dtype=np.uint8) * 255\n",
    "\n",
    "plt.subplots(1, 3, figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(black, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(132)\n",
    "plt.imshow(gray, cmap='gray', vmin=0, vmax=255)\n",
    "plt.subplot(133)\n",
    "plt.imshow(white, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P2. Explique la utilidad de vmin y vmax y cuando es importante tenerlo en cuenta:\n",
    "\n",
    "La funci√≥n de Vmin y Vm√°x son utilizados como par√°metros que establecen el rango de valores que se analizar√° en los colores de la imagen, lo cual estos par√°metros son utilizados por la biblioteca de matplotlib, en el que Vm√≠nimo solo se emplea los datos m√≠nimos que se mapearan al color m√°s bajo del colormap, en cambio cuando se usa Vm√°ximo es definir el l√≠mite m√°ximo de valor de los datos que se mapear√°n al color m√°s alto del colormap (mapa de color), entonces los valores que no est√°n en ese rango se mostran como color m√≠nimo para menor al Vmin y color m√°ximo mayores al Vm√°x.\n",
    "\n",
    "Por lo tanto, se utilizan estos par√°metros para:\n",
    "\n",
    "-\tLa visualizaci√≥n de im√°genes en escala de grises o de colores √∫nicos, entonces Matplolib genera un ajuste para los valores m√≠nimos y m√°ximos de la imagen.\n",
    "-\tPermite la comparaci√≥n de im√°genes con un mismo rango de colores, para poder visualizar detalladamente la intensidad de color como un mismo valor de datos.\n",
    "-\tPermite la optimizaci√≥n de los valores importantes a analizar porque en un conjunto de datos que presenta las im√°genes, suelen tener datos muy elevados que no contribuyen a la informaci√≥n que se requiere utilizar, por lo cual es que con Vmax y Vmin se logra acortar los datos y as√≠ se pueda utilizar toda la escala para mejorar el contraste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2IV5buauF9q"
   },
   "source": [
    "### **Escalando los colores y dibujando dentro de una imagen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vu8ilsqQuF9r",
    "outputId": "f4f52532-9a49-4aa0-920b-aef96ab869d4"
   },
   "outputs": [],
   "source": [
    "black = np.zeros([100, 100], dtype=np.uint8)\n",
    "black[10:90, 30:60] = 128\n",
    "\n",
    "black = black/255\n",
    "\n",
    "plt.imshow(black, cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P3. Que tipo de dato es la imagen despues de dividir entre 255? \n",
    "- Al utilizar black de tipo unit8(un enetero sin digno de 8 bits), lo cual su rango est√° entre 0 a 255, es asi que al dividir entre 255, se genera datos de tipo float64(n√∫meros reales en doble precisi√≥n), ya que la divisi√≥n produce 0.0 y 1.0, lo que se concluye que no pueden ser n√∫meros enteros, por lo tanto son de tipo float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(black)\n",
    "# numpy.ndarray\n",
    "black.dtype\n",
    "# dtype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P4. Explique como funcionan los ejes en las im√°genes mostradas en python.\n",
    "\n",
    "- La figura al estar analizada en 2D,se toma como origen al (0,0), el que se encuentra arriba y a la izquierda, pero esto se debe a que en las m√°quinas se analiza las im√°genes digitales en el eje Y desde arriba hacia abajo porque se almacena l√≠nea por l√≠nea desde arriba, es por ello que en la imagen se puede ver esta convecci√≥n donde el eje X crece de izquierda a derecha, pero el eje Y lo hace de arriba hacia abajo por la convecci√≥n digital,considerando que la libreri√≠ de matplotlib muestra la fila 0 en la parte superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPBOnkA-uF9s"
   },
   "source": [
    "### **Creando formas dentro de una imagen con numpy y OpenCV**\n",
    " * cv2.rectangle(img, pt1, pt2, (color RGB), thickness= )\n",
    " * cv2.line(img, pt1, pt2, (color RGB),thickness= )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCI7sVc5uF9t",
    "outputId": "65df26c1-f2d7-4376-d119-6d2d7f6f7915"
   },
   "outputs": [],
   "source": [
    "black = np.zeros([200, 200, 3], dtype=np.uint8)\n",
    "COLOR = (0,0,255)\n",
    "PT1 = (5, 20)\n",
    "PT2 = (100,120)\n",
    "cv2.rectangle(black, PT1, PT2, COLOR, thickness=-1)\n",
    "cv2.line(black, PT1, PT2, (255, 0, 0), thickness=2)\n",
    "\n",
    "plt.imshow(black[..., ::-1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKfnZnf9uF9t"
   },
   "source": [
    "* cv2.circle(img, (centro), radio, (color), thickness=)\n",
    "\n",
    "* cv2.putText(img, \"Texto\", (punto de inicio), fuente, tama√±o, (color), thickness=)\n",
    " * fuente -> cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBn_ld1LuF9u",
    "outputId": "9d5fe295-298e-4cd9-b03c-1831b9718867"
   },
   "outputs": [],
   "source": [
    "black = np.zeros([200, 200, 3], dtype=np.uint8)\n",
    "COLOR = (0,0,255)\n",
    "PT1 = (0, 20)\n",
    "PT2 = (100,120)\n",
    "\n",
    "# cv2.rectangle(black, PT1, PT2, COLOR, thickness=-1)\n",
    "# cv2.line(black, PT1, PT2, (255, 0, 0), thickness=2)\n",
    "cv2.circle(black, (100,100), 50, (255,0,0), thickness=2)\n",
    "cv2.putText(black, \"Verde\", (20,175), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), thickness=1)\n",
    "\n",
    "plt.imshow(black[..., ::-1], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQCOPzM7uF9w"
   },
   "source": [
    "### Cambiar tama√±o de una imagen con OpenCV-> [resize](https://pythonexamples.org/python-opencv-cv2-resize-image/)\n",
    "\n",
    "cv2.resize(img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "*******\n",
    "* 1. `cv2.INTER_NEAREST`\n",
    "\n",
    "Usa el valor del p√≠xel m√°s cercano sin interpolaci√≥n.  \n",
    "**Ventajas:** Muy r√°pido computacionalmente.  \n",
    "**Desventajas:** Produce im√°genes pixeladas y con bordes marcados.  \n",
    "**Uso t√≠pico:** Mapas, gr√°ficos o im√°genes con pocos colores.  \n",
    "\n",
    "\n",
    "\n",
    "* 2. `cv2.INTER_LINEAR`\n",
    "\n",
    "Calcula el nuevo valor de p√≠xel como una combinaci√≥n lineal de los vecinos m√°s cercanos.  \n",
    "**Ventajas:** Buen equilibrio entre calidad y velocidad.  \n",
    "**Desventajas:** Puede generar una ligera suavidad o p√©rdida de nitidez.  \n",
    "**Uso t√≠pico:** Reducciones o ampliaciones moderadas (es el m√©todo por defecto de OpenCV).  \n",
    "\n",
    "\n",
    "\n",
    "* 3. `cv2.INTER_AREA`\n",
    "\n",
    "Calcula el promedio de los p√≠xeles del √°rea correspondiente.  \n",
    "**Ventajas:** Muy bueno para reducir im√°genes (downscaling), evita aliasing.  \n",
    "**Desventajas:** No se recomienda para ampliaciones.  \n",
    "**Uso t√≠pico:** Reducci√≥n de im√°genes o creaci√≥n de miniaturas.  \n",
    "\n",
    "\n",
    "* 4. `cv2.INTER_CUBIC`\n",
    "\n",
    "Usa interpolaci√≥n bic√∫bica considerando un vecindario de 4√ó4 p√≠xeles.  \n",
    "**Ventajas:** Produce im√°genes suaves y detalladas con buena calidad visual.  \n",
    "**Desventajas:** M√°s lento que LINEAR y AREA.  \n",
    "**Uso t√≠pico:** Ampliaciones o procesamiento donde la calidad es importante.  \n",
    "\n",
    "\n",
    "* 5. `cv2.INTER_LANCZOS4`\n",
    "\n",
    "Utiliza un filtro sinc de 8√ó8 p√≠xeles para obtener una interpolaci√≥n de muy alta calidad.  \n",
    "**Ventajas:** M√°xima fidelidad visual tanto al ampliar como al reducir.  \n",
    "**Desventajas:** M√°s lento y m√°s exigente computacionalmente.  \n",
    "**Uso t√≠pico:** Aplicaciones de edici√≥n o an√°lisis donde la precisi√≥n de detalle es prioritaria.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeR_vjqhuF9w",
    "outputId": "0c0a0d8e-af87-4e4f-f99d-c4e160f9bab1"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgSRC)[...,::-1]\n",
    "\n",
    "# img_resize_small = cv2.resize(img, None, fx=1/2, fy=1/3, interpolation=cv2.INTER_LINEAR)\n",
    "img_resize_small = cv2.resize(img, (150,150), interpolation=cv2.INTER_LANCZOS4)\n",
    "img_resize_big = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "print(img.shape)\n",
    "plt.subplots(1, 3, figsize=(15,5))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img)\n",
    "plt.subplot(132)\n",
    "plt.imshow(img_resize_small)\n",
    "plt.subplot(133)\n",
    "plt.imshow(img_resize_big)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P5. Cree un bucle para mostrar la im√°gen original y el efecto de las 5 diferentes interpolaciones al escalar a la mitad su ancho y largo. Se nota la diferencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "img = cv2.imread(imgSRC)[..., ::-1]\n",
    "\n",
    "# Lista de interpolaciones y sus nombres\n",
    "interpolations = [\n",
    "    (\"NEAREST\", cv2.INTER_NEAREST),\n",
    "    (\"LINEAR\", cv2.INTER_LINEAR),\n",
    "    (\"AREA\", cv2.INTER_AREA),\n",
    "    (\"CUBIC\", cv2.INTER_CUBIC),\n",
    "    (\"LANCZOS4\", cv2.INTER_LANCZOS4)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Mostrar imagen original\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Original\\n{img.shape[1]}x{img.shape[0]}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Bucle sobre las interpolaciones\n",
    "for i, (name, method) in enumerate(interpolations, start=2):\n",
    "    # Medir tiempo\n",
    "    start = time.time()\n",
    "    # Redimensionar a 20% del tama√±o\n",
    "    img_resized = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=method)\n",
    "    end = time.time()\n",
    "\n",
    "    # Mostrar\n",
    "    plt.subplot(2, 3, i)\n",
    "    plt.imshow(img_resized)\n",
    "    plt.title(f\"{name}\\n{img_resized.shape[1]}x{img_resized.shape[0]}\\n{(end-start)*1000:.1f} ms\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el c√≥digo se utiliz√≥ la funci√≥n cv2.resize de OpenCV dentro de un bucle para aplicar cinco m√©todos de interpolaci√≥n diferentes (`NEAREST`, `LINEAR`, `AREA`, `CUBIC` y `LANCZOS4`) al reducir una imagen al 50 % de su tama√±o original.Esta escala de reducci√≥n no es muy grande (solo 0.5√ó), los p√≠xeles originales ya est√°n lo suficientemente cerca, as√≠ que todos los m√©todos generan resultados similares.El √∫nico que puede notarse un poco distinto es NEAREST, porque no interpola (solo copia el p√≠xel m√°s cercano), lo que a veces genera un efecto m√°s ‚Äúcuadriculado‚Äù."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_ffJuWQuF9x"
   },
   "source": [
    "### Mostrar imagen con OpenCV en una ventana\n",
    "HACER ESTO FUERA DE UN NOTEBOOK\n",
    "\n",
    "cv2.imshow(nombre de ventana, imagen)\n",
    "* cv2.waitKey(0)  \n",
    "* cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QaxUa0TduF9x"
   },
   "outputs": [],
   "source": [
    "# img = cv2.imread(imgSRC)\n",
    "# cv2.imshow('Robot Sofia', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "imgSRC = 'lab_images/robotSofia.jpg'  \n",
    "\n",
    "# Leer la imagen\n",
    "img = cv2.imread(imgSRC)\n",
    "\n",
    "# Verificar que la imagen se haya cargado\n",
    "if img is None:\n",
    "    print(\"No se pudo cargar la imagen. Verifica la ruta.\")\n",
    "else:\n",
    "    # Mostrar la imagen en una ventana\n",
    "    cv2.imshow('Robot Sofia', img)\n",
    "\n",
    "    # Esperar hasta que presiones una tecla\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Cerrar todas las ventanas\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ4oBnOruF9y"
   },
   "source": [
    "# <font color=#FF0000>Operaciones de punto</color>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ss-i9KSuF9y"
   },
   "source": [
    "### Negativo de una imagen\n",
    "\n",
    "* s = 255- f(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Vb3ixzEuF9y",
    "outputId": "b6cc72d2-cfc9-4aa5-e73d-e75d7bc8a730"
   },
   "outputs": [],
   "source": [
    "r = cv2.imread(imgSRC)[..., ::-1]/255\n",
    "s = 1 - r\n",
    "plt.imshow(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oq3fpSbAuF9z"
   },
   "source": [
    "### Tranformacion Logar√≠tmica\n",
    "* s = c.log(1+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXINlyjMuF9z",
    "outputId": "79f40e84-a72b-470c-ca87-4e98a1609fa4"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgSRC, 0)\n",
    "\n",
    "fft_2 = np.fft.fft2(img)\n",
    "fft_2_abs = np.abs(fft_2)\n",
    "fft_2_abs = np.fft.fftshift(fft_2_abs)\n",
    "fft_2_abs_log = np.log(fft_2_abs+1)\n",
    "\n",
    "plt.figure(figsize=(10,15))\n",
    "plt.imshow(fft_2_abs_log, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P6. Compruebe cuanto son los valores m√≠nimo y m√°ximo de la imagen original y de la im√°gen que muestra el espectro. Luego describa que efecto tuvo la transformaci√≥n logar√≠tmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lab_images/robotSofia.jpg', 0)\n",
    "\n",
    "# --- 1. Valores m√≠nimo y m√°ximo de la imagen original ---\n",
    "min_original = np.min(img)\n",
    "max_original = np.max(img)\n",
    "print(f\"Imagen Original ‚Üí M√≠n: {min_original}, M√°x: {max_original}\")\n",
    "\n",
    "# --- 2. C√°lculo del espectro de Fourier (misma imagen) ---\n",
    "fft_2 = np.fft.fft2(img)\n",
    "fft_2_abs = np.abs(fft_2)\n",
    "fft_2_abs = np.fft.fftshift(fft_2_abs)\n",
    "\n",
    "# --- 3. Aplicar la transformaci√≥n logar√≠tmica ---\n",
    "fft_2_abs_log = np.log(fft_2_abs + 1)\n",
    "\n",
    "# --- 4. Valores m√≠nimo y m√°ximo del espectro logar√≠tmico ---\n",
    "min_fft = np.min(fft_2_abs_log)\n",
    "max_fft = np.max(fft_2_abs_log)\n",
    "print(f\"Espectro Logar√≠tmico ‚Üí M√≠n: {min_fft}, M√°x: {max_fft}\")\n",
    "\n",
    "# --- 5. Mostrar las dos im√°genes (misma fuente) ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Imagen Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(fft_2_abs_log, cmap='gray')\n",
    "plt.title('Espectro (Transformaci√≥n Logar√≠tmica)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen original, mostrada a la izquierda, corresponde a la fotograf√≠a en escala de grises del robot, con valores de intensidad que van de 0 a 255. Esto indica que ocupa todo el rango de niveles de gris posibles, mostrando un buen contraste entre las zonas claras e iluminadas del rostro y las √°reas oscuras del fondo.  \n",
    "\n",
    "A la derecha se observa el espectro obtenido mediante la Transformada de Fourier 2D, al que se le aplic√≥ una transformaci√≥n logar√≠tmica pa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBKNWKiAuF9z"
   },
   "source": [
    "### Transformaci√≥n Gamma\n",
    "###   $s=cr^\\gamma $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0R2mipuuF90",
    "outputId": "d965ecc8-2011-482d-cb40-44ef8022b9a2"
   },
   "outputs": [],
   "source": [
    "r = cv2.imread(imgSRC)[..., ::-1]/255\n",
    "s = r**0.5\n",
    "plt.imshow(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YJ_HKD5uF90"
   },
   "source": [
    "### Transformaci√≥n arbitraria\n",
    "* ####   Especificar una funcion de transformacion\n",
    "cv2.LUT(img, lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcion_ejemplo = np.arange(256)\n",
    "funcion_ejemplo[90:140] = 200\n",
    "\n",
    "img = cv2.imread(imgSRC, 0)\n",
    "img_out = funcion_ejemplo[img]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"Imagen original\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(funcion_ejemplo, color=\"blue\")\n",
    "plt.title(\"Funci√≥n de transformaci√≥n\")\n",
    "plt.xlabel(\"Nivel de entrada\")\n",
    "plt.ylabel(\"Nivel de salida\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_out, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.title(\"Imagen transformada\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros(256)\n",
    "\n",
    "for pix in range(256):\n",
    "    if pix < 50:\n",
    "        r[pix] = 30/50*(pix-50) + 30\n",
    "    if 50 <=pix < 100:\n",
    "        r[pix] = 190/50*(pix-50) + 30\n",
    "    if 100 <=pix:\n",
    "        r[pix] = 35/155*(pix-100) + 220\n",
    "\n",
    "plt.plot(r)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRdhAwqeuF90",
    "outputId": "6c83005f-5e27-4708-9032-e65930169be5"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgSRC,0)\n",
    "s=cv2.LUT(img, funcion_ejemplo)\n",
    "plt.figure(figsize=(8,10))\n",
    "plt.imshow(s, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0HUz9QauF91"
   },
   "source": [
    "### Divisi√≥n en capas de bits \n",
    "\n",
    "* np.bitwise_and(imagen, bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HThy93X5uF91",
    "outputId": "2f426c78-cedc-4067-81a7-5c6e229d083a"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(imgSRC, 0)\n",
    "\n",
    "img7 = cv2.bitwise_and(img, 128)\n",
    "img6 = cv2.bitwise_and(img, 64)\n",
    "img5 = cv2.bitwise_and(img, 32)\n",
    "img4 = cv2.bitwise_and(img, 16)\n",
    "img3 = cv2.bitwise_and(img, 8)\n",
    "img2 = cv2.bitwise_and(img, 4)\n",
    "img1 = cv2.bitwise_and(img, 2)\n",
    "img0 = cv2.bitwise_and(img, 1)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(331)\n",
    "plt.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.subplot(332)\n",
    "plt.imshow(img0, cmap=\"gray\")\n",
    "plt.subplot(333)\n",
    "plt.imshow(img1, cmap=\"gray\")\n",
    "plt.subplot(334)\n",
    "plt.imshow(img2, cmap=\"gray\")\n",
    "plt.subplot(335)\n",
    "plt.imshow(img3, cmap=\"gray\")\n",
    "plt.subplot(336)\n",
    "plt.imshow(img4, cmap=\"gray\")\n",
    "plt.subplot(337)\n",
    "plt.imshow(img5, cmap=\"gray\")\n",
    "plt.subplot(338)\n",
    "plt.imshow(img6, cmap=\"gray\")\n",
    "plt.subplot(339)\n",
    "plt.imshow(img7, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uV6Uwe2puF92"
   },
   "source": [
    "#### Mostrar solo las 5 capas mas significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbQRGD4yuF92",
    "outputId": "f1f43260-2e2f-4b5b-db38-6b63b1d12534"
   },
   "outputs": [],
   "source": [
    "img_comprimida = img7+ img6 + img5 + img4 + img3 + img2\n",
    "plt.imshow(img_comprimida, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P7. Si usted quisiera encriptar un  mensaje dentro de una fotograf√≠a, como lo har√≠a?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiera encriptar un mensaje dentro de una fotograf√≠a, utilizar√≠a una t√©cnica llamada **esteganograf√≠a**, que consiste en ocultar informaci√≥n dentro de una imagen sin alterar visiblemente su apariencia. Una forma pr√°ctica de hacerlo ser√≠a mediante la **modificaci√≥n de los bits menos significativos (LSB)** de cada p√≠xel. Estos bits tienen un efecto m√≠nimo en la apariencia visual, por lo que pueden reemplazarse por los bits del mensaje que se desea ocultar sin que el ojo humano perciba cambios.  \n",
    "\n",
    "Por ejemplo, podr√≠a convertir el mensaje a binario y luego insertar sus bits en los **bits menos significativos de los valores de intensidad** de la imagen. Para recuperar el mensaje, bastar√≠a con leer nuevamente esos bits. Este m√©todo aprovecha el conocimiento sobre la **divisi√≥n en capas de bits**, ya que permite identificar cu√°les capas tienen menor impacto visual y son m√°s adecuadas para ocultar informaci√≥n sin afectar la calidad perceptible de la imagen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJEMPLO CODE:\n",
    "import os\n",
    "# ---------- OCULTAR EL MENSAJE ----------\n",
    "def ocultar_mensaje(imagen_path, mensaje, salida_path):\n",
    "    img = cv2.imread(imagen_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\" No se pudo cargar la imagen de entrada.\")\n",
    "        return\n",
    "\n",
    "    # Convertir mensaje a binario\n",
    "    mensaje_binario = ''.join([format(ord(i), '08b') for i in mensaje])\n",
    "    mensaje_binario += '1111111111111110'  # marcador de fin\n",
    "\n",
    "    data_index = 0\n",
    "    bin_len = len(mensaje_binario)\n",
    "\n",
    "    # Aplanar la imagen\n",
    "    flat_img = img.flatten()\n",
    "\n",
    "    if bin_len > len(flat_img):\n",
    "        print(\" El mensaje es demasiado largo para esta imagen.\")\n",
    "        return\n",
    "\n",
    "    # Insertar los bits (forma segura)\n",
    "    for i in range(bin_len):\n",
    "        flat_img[i] = (flat_img[i] & 254) | int(mensaje_binario[i])\n",
    "\n",
    "    # Reconstruir y guardar\n",
    "    img_oculta = flat_img.reshape(img.shape)\n",
    "    cv2.imwrite(salida_path, img_oculta)\n",
    "    print(f\" Mensaje oculto en: {os.path.abspath(salida_path)}\")\n",
    "\n",
    "\n",
    "# ---------- RECUPERAR EL MENSAJE ----------\n",
    "def recuperar_mensaje(imagen_path):\n",
    "    img = cv2.imread(imagen_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\" No se pudo cargar la imagen para recuperar el mensaje.\")\n",
    "        return\n",
    "\n",
    "    flat_img = img.flatten()\n",
    "    bits = [str(pixel & 1) for pixel in flat_img]\n",
    "    mensaje_binario = ''.join(bits)\n",
    "\n",
    "    caracteres = [mensaje_binario[i:i+8] for i in range(0, len(mensaje_binario), 8)]\n",
    "\n",
    "    mensaje = \"\"\n",
    "    for c in caracteres:\n",
    "        if c == '11111111':  # marcador de fin\n",
    "            break\n",
    "        mensaje += chr(int(c, 2))\n",
    "\n",
    "    print(\"üì© Mensaje recuperado:\", mensaje)\n",
    "\n",
    "\n",
    "# ---------- EJEMPLO DE USO ----------\n",
    "ocultar_mensaje('lab_images/robotSofia.jpg', 'Hola, este es un mensaje secreto!', 'imagen_oculta.png')\n",
    "recuperar_mensaje('imagen_oculta.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQpzPAdPuF92"
   },
   "source": [
    "### Histograma de una imagen\n",
    "* np.histogram(img, bins, [rango de datos])  (requiere plotear)\n",
    "* plt.hist(img.ravel(), bins, [rango de datos])\n",
    "* cv2.calcHist([img], [canal], mascara,[bins], [rango de datos])\n",
    "\n",
    "#####  Normalizar CDF $ \\frac{cdf*hist.max}{cdf.max} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1639719163635,
     "user": {
      "displayName": "Emerson Maximo Asto Rodriguez",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7HXYl95AYs_NqVtsvVJynjbO-HU0tmgZuUXVE=s64",
      "userId": "17877311400331783159"
     },
     "user_tz": 300
    },
    "id": "s7EGEM2ZuF92"
   },
   "outputs": [],
   "source": [
    "#Numpy\n",
    "img = cv2.imread(\"./lab_images/rayx.jpg\")[..., ::-1]\n",
    "img_gray = img[..., 0]\n",
    "\n",
    "hist, bins = np.histogram(img_gray, 256, [0, 256])\n",
    "plt.bar(np.arange(256), hist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJdwffXluF93",
    "outputId": "46d19a0c-5fd1-42fd-d2cb-a807247317ad"
   },
   "outputs": [],
   "source": [
    "#matplotlib\n",
    "hist = plt.hist(img_gray.ravel(), 256, [0,256], density=True)\n",
    "cdf = np.cumsum(hist[0])\n",
    "cdf_norm = cdf*(hist[0].max())/(cdf.max())\n",
    "plt.plot(cdf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtUCyoPwuF94",
    "outputId": "7d7e4f24-a0c2-4bd4-b8fa-384c4471361f"
   },
   "outputs": [],
   "source": [
    "# openCV\n",
    "color = (\"r*-\", \"gs-\", \"b^-\")\n",
    "for i, col in enumerate(color):\n",
    "    hist = cv2.calcHist([img], [i], None,[256], [0,256])\n",
    "    plt.plot(hist, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vgt4RCItuF94"
   },
   "source": [
    "### Equalizaci√≥n de Histograma\n",
    "* cv2.equalizeHist(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qajkW_jtuF94",
    "outputId": "cf59fc74-b113-481f-f169-0f8ace98ac83"
   },
   "outputs": [],
   "source": [
    "#Numpy\n",
    "img = cv2.imread(\"./lab_images/rayx.jpg\")[..., ::-1]\n",
    "img_gray = img[..., 0]\n",
    "\n",
    "img_equ = cv2.equalizeHist(img_gray)\n",
    "plt.imshow(img_equ, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P8. Que sucede durante la equalizaci√≥n de histograma?\n",
    "La equalizaci√≥n del histograma se encarga de redistribuir los niveles de intensidad de una imagen para que su histograma sea m√°s plano y ocupe mejor todo el rango din√°mico. El objetivo es aumentar el contraste, especialmente cuando la imagen usa solo una parte del rango de intensidades. Calcula la distribuci√≥n acumulada de los niveles de gris, eso usa para reasignar cada valor de intensidad a uno nuevo que expanda las zonas densas del histograma y como resultado se obtiene una intensidad menos agrupada, detalles m√°s visibles en √°reas oscuras o brillantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RH7X7rDhuF94"
   },
   "source": [
    "### Equalizaci√≥n de Histograma adaptativa\n",
    "*clahe = createCLAHE() \n",
    "*clahe.apply(img) \n",
    "\n",
    "* [CLAHE Histogram Eqalization](https://www.geeksforgeeks.org/clahe-histogram-eqalization-opencv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_3EUettuF94",
    "outputId": "4158fa96-28ae-4414-e6b9-05e9d6c19c85"
   },
   "outputs": [],
   "source": [
    "#Numpy\n",
    "img = cv2.imread(\"./lab_images/rayx.jpg\")[..., ::-1]\n",
    "img_gray = img[..., 0]\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=5)\n",
    "final_img = clahe.apply(img_gray) + 60\n",
    "\n",
    "plt.imshow(final_img, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P8. Que diferencias ve usted en la equalizaci√≥n normal y la equalizaci√≥n adaptativa (CLAHE)\n",
    "Se observa una gran diferencia entre ambas im√°genes, la imagen que usa equalizaci√≥n normal se ve mucho m√°s brillante y m√°s oscura en ciertas zonas, mientra que la imagen que usa CLAHE no, no se ve tan saturada, hasta se puede ver mejor en las zonas oscuras, se puede ver con m√°s claridad, esto se debe a que CLAHE divide la imagen en partes m√°s peque√±as y ajusta el constraste de cada parte por separado, lo que ayuda a obtener una imagen con una mejor visibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLK7rhi_uF94"
   },
   "source": [
    "## Histogram Matching\n",
    "\n",
    "Aplique a una foto suya el estilo de la monalisa usando histogram matching. Use estas gu√≠as como referencia\n",
    "\n",
    "https://www.pyimagesearch.com/2021/02/08/histogram-matching-with-opencv-scikit-image-and-python/\n",
    "https://automaticaddison.com/how-to-do-histogram-matching-using-opencv/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "\n",
    "#Lectura de imagenes\n",
    "src=cv2.imread(\"./lab_images/original.jpg\")\n",
    "ref=cv2.imread(\"./lab_images/referencia.jpeg\")\n",
    "\n",
    "#Conversio de BGR a RGB\n",
    "src_rgb=cv2.cvtColor(src, cv2.COLOR_BGR2RGB)\n",
    "ref_rgb=cv2.cvtColor(ref, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Uso de la funci√≥n de correspondencia de histogramas\n",
    "match=-1 if src_rgb.ndim == 3 else None\n",
    "matched = exposure.match_histograms(src_rgb, ref_rgb,channel_axis=match)\n",
    "\n",
    "#Mostrar las imagenes\n",
    "# Funci√≥n para convertir cualquier imagen a uint8 0-255 para mostrar correctamente\n",
    "def to_uint8(img):\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = np.asarray(img)\n",
    "    if img.dtype == np.uint8:\n",
    "        return img\n",
    "    # Normalizar float u otros tipos a 0-255\n",
    "    mi, ma = img.min(), img.max()\n",
    "    if ma == mi:\n",
    "        return np.zeros_like(img, dtype=np.uint8)\n",
    "    img_norm = (img - mi) / (ma - mi)\n",
    "    return (img_norm * 255).astype(np.uint8)\n",
    "\n",
    "src_disp = to_uint8(src_rgb)\n",
    "ref_disp = to_uint8(ref_rgb)\n",
    "matched_disp = to_uint8(matched)\n",
    "\n",
    "# Mostrar 3 im√°genes en fila\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "images = [src_disp, ref_disp, matched_disp]\n",
    "titles = [\"Fuente\", \"Referencia\", \"Resultado\"]\n",
    "\n",
    "for ax, im, title in zip(axes, images, titles):\n",
    "    if im is None:\n",
    "        ax.text(0.5, 0.5, \"Imagen no encontrada\", ha='center')\n",
    "    else:\n",
    "        # si la imagen es grayscale (2D) usar cmap='gray'\n",
    "        if im.ndim == 2:\n",
    "            ax.imshow(im, cmap='gray')\n",
    "        else:\n",
    "            ax.imshow(im)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que gracias a la funci√≥n match_histogram se puede cambiar el contraste y la distribuci√≥n de colores de una imagen con respecto a una imagen de referencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema de investigaci√≥n\n",
    "\n",
    "Elija su tema de investigaci√≥n de la lista proporcionada por el docente o proponga un nuevo tema. Su grupo puede ser √∫nicamente de 3 estudiantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTEGRANTES\n",
    "\n",
    "1.Bonifacio Julian Royer\n",
    "\n",
    "2.Castillo Avila Renzo\n",
    "\n",
    "3.Vasques Cuevas Gustavo"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practica 06 - Introducci√≥n a OpenCV - Operaciones de punto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
