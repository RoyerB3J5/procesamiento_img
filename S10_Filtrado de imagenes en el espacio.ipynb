{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3PvV_WVz4S8"
   },
   "source": [
    "**ESCUELA DE INGENIERÍA MECATRÓNICA**\n",
    "\n",
    "## `PROCESAMIENTO DIGITAL DE SEÑALES E IMÁGENES`\n",
    "\n",
    "### `Docente: Ms. Ing. Emerson Maximo Asto Rodriguez`\n",
    "\n",
    "```\n",
    "Práctica 10: Filtrado en el espacio\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpJ-wYnOz4TB"
   },
   "source": [
    "### 1. Implemente un algoritmo que permita realizar la correlacion 2D de una imagen de MxN con una mascara de mxn\n",
    "* El algoritmo debe retornar una imagen de las mismas dimensiones que la imagen de entrada, recuerde que el \"padding\" usualmente se hace con ceros, no obstante se puede duplicar filas o columnas del borde, o hacerlo mediante un espejo sobre el borde.*\n",
    "\n",
    "* El algoritmo tambien puede obtener la solución sin necesidad del \"padding\", agregando varias condicionales que permitan solo ponderar con los datos coincidentes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3kfJcdCz4TC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5Y5cW2Wz4TE"
   },
   "outputs": [],
   "source": [
    "def filtro_espacial(imagen, filtro):\n",
    "    M, N = imagen.shape\n",
    "    m, n = filtro.shape\n",
    "\n",
    "    filas_add = (m - 1) // 2\n",
    "    columnas_add = (n - 1) // 2\n",
    "\n",
    "    img_pad = np.zeros((M + m - 1, N + n - 1), dtype=np.float32)\n",
    "    img_pad[filas_add: filas_add + M, columnas_add: columnas_add + N] = imagen\n",
    "\n",
    "    resultado = np.zeros_like(imagen)\n",
    "\n",
    "    for i in np.arange(filas_add, filas_add + M):\n",
    "        for j in np.arange(columnas_add, columnas_add + N):\n",
    "            vecindad = img_pad[i-filas_add: i+filas_add+1, j-columnas_add: j+columnas_add+1]\n",
    "            multiplicacion = vecindad * filtro\n",
    "            resultado[i-filas_add, j-columnas_add] = np.sum(multiplicacion)\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante el uso de técnicas de padding en la aplicación de filtros espaciales? \n",
    "<p align=\"justify\">\n",
    "Debido a que el padding en filtros espaciales nos permiten procesar mejor los píxeles de los bordes de la imagen, ya que sin esto la imagen original empezaría a encogerse o desaparecerse mientras más filtros se vayan poniendo sin padding, es por ello que se utiliza este ante de aplicar el filtro y se asegura de que no se distorsione en los bordes  y que todos los bordes sean procesados, ya que se genera una ampliación de las dimensiones para poder utilizar el filtro sin preocupación de perder el tamaño original de la imagen.\n",
    "<p>\n",
    "2. Explica qué es un kernel (o máscara) en un filtro espacial y cómo influye su tamaño en el procesamiento de imágenes.\n",
    "<p align=\"justify\">\n",
    "Un kernel o máscara es una pequeña matriz de números, en el que calculará (matemáticamente)el nuevo valor de un pixel a partir de los valores de sus pixeles vecinos, por lo que este kernel combina toda la información de los pixeles vecinos para obtener un nuevo valor en cada posición de la imagen.\n",
    "Su tamaño influye en la intensidad y escala del efecto(al tener un kernel más pequeño solo se centra en los vecinos inmediatos, en cambio un kernel grande tiene un mayor rango de vecinos y así se obtiene un efecto más fuerte y pronunciado, lo que genera eliminación de detalles pequeños).\n",
    "Además, influye en el costo computacional ya que su tamaño definirá la cantidad de cálculos que debe hacerse por cada píxel.\n",
    "Por otro lado, también influye en la preservación de detalles, ya que tener un kernel pequeño asegura que se tenga mejor los detalles de alta frecuencia(texturas, bordes finos), en caso contrario, un kernel grande como se mencionó anteriormente, ocasiona que se agregue información sobre un área por lo que se borra o promedia los detalles de alta frecuencia, por lo que se prefiere si se requiere eliminar demasiado ruido.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bze8c7nSz4TE",
    "outputId": "3c6bb99e-7e8c-4788-c8c8-5a94864e9cc2"
   },
   "outputs": [],
   "source": [
    "img = np.arange(100).reshape(10,10)\n",
    "filtro = np.round(np.ones((5,7))/35, 3)\n",
    "\n",
    "print(img)\n",
    "print(filtro)\n",
    "\n",
    "img_filtrada = filtro_espacial(img, filtro)\n",
    "print(\"resultado \\n\", img_filtrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onPmcFiOz4TG",
    "outputId": "e0804251-a164-4c42-bab3-8307a517fa16"
   },
   "outputs": [],
   "source": [
    "img_ruido = cv2.imread('lab_images/ruido.png', 0)/255\n",
    "\n",
    "filtro = np.ones((5,7))\n",
    "filtro = filtro/np.sum(filtro)\n",
    "\n",
    "img_ruido_filtrada = filtro_espacial(img_ruido, filtro)\n",
    "\n",
    "plt.subplots(1,2, figsize=(15,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_ruido, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_ruido_filtrada, cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8ijKszoz4TG"
   },
   "source": [
    "### 2.- Implemente un algoritmo que permita mejorar solo los pixeles oscuros y de bajo contraste\n",
    "*Puede modificar levemente el algoritmo realizado en el enunciado **1** para lograr el objetivo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RicBltssz4TH"
   },
   "outputs": [],
   "source": [
    "def filtro_espacial_estadistico(imagen, selem = np.ones((3,3))):\n",
    "    media_global = np.mean(imagen)\n",
    "    desv_global = np.std(imagen)\n",
    "    print(\"Media global:\", media_global*0.3)\n",
    "    print(\"Desviacion global:\", desv_global)\n",
    "\n",
    "    M, N = imagen.shape\n",
    "    m, n = selem.shape\n",
    "\n",
    "    filas_add = (m - 1) // 2\n",
    "    columnas_add = (n - 1) // 2\n",
    "\n",
    "    img_pad = np.zeros((M + m - 1, N + n - 1))\n",
    "    img_pad[filas_add: filas_add + M, columnas_add: columnas_add+ N ] = imagen\n",
    "\n",
    "    resultado = np.zeros_like(imagen)\n",
    "\n",
    "    for i in np.arange(filas_add, filas_add + M):\n",
    "        for j in np.arange(columnas_add, columnas_add + N):\n",
    "            vecindad = img_pad[i-filas_add: i+filas_add+1, j-columnas_add: j+columnas_add+1]\n",
    "\n",
    "            multiplicacion = vecindad * selem\n",
    "\n",
    "            media_local = np.mean(multiplicacion)\n",
    "            desv_local = np.std(multiplicacion)\n",
    "\n",
    "            if (media_local<media_global) and (desv_local<0.8*desv_global) and (desv_local>0.2*desv_global):\n",
    "                resultado[i-filas_add, j-columnas_add] = img_pad[i,j]*3\n",
    "            else:\n",
    "                resultado[i-filas_add, j-columnas_add] = img_pad[i,j]\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Cuál es el objetivo de este algoritmo y qué tipo de imágenes se benefician más de su aplicación?\n",
    "<p align=\"justify\">\n",
    "Este algoritmo está relacionado con filtros espaciales estadísticos, lo cual permite analizar las características de las estadísticas locales (media y desviación estándar) de la imagen, para de esa manera modificarla selectivamente los pixeles, entonces se requiere destacar ciertas zonas de la imagen sin tener que perjudicar o alterar el contenido, en otras palabras, selecciona los pixeles que se deben modificar según las condiciones de la manera local y global.\n",
    "Por otra parte, este filtro al querer alzar las imágenes con sombras u oscuras, entonces beneficias a aquellas que presentan demasiada oscuridad y no afecta al fondo, también aquellas que están presente a contraluz(una persona en una zona oscura y relativamente suave, le subirá el brillo sin modificar nada a lo que está a su alrededor ya que se considerará una media local alta), también es sobresaliente en imágenes con sombras profundas, entonces le subirá el brillo aquellas partes oscuras e incluso para las imágenes del sector salud o científico.\n",
    "<p>\n",
    "\n",
    "2. Vecindad y Kernel: ¿Cómo se define la vecindad de un píxel en este código y cuál es la importancia de la variable selem en este contexto?\n",
    "<p align=\"justify\">\n",
    "La vecindad de un pixel se define por el tamaño del kernel o elemento estructurante (selem), en el cual por defecto se ha establecido en el código como uno de 3x3 ( np.ones((3,3)))\n",
    "Además, en el código la variable que dice \"vecindad\", al presentar (i,j), se está generando una extracción de los valores vecinos centrados a ese pixel.\n",
    "<p align=\"justify\">\n",
    "\n",
    "Entonces el rol que cumple la variable selem en este caso es para:\n",
    "<p align=\"justify\">\n",
    "\n",
    "- Definir el alcance o tamaño espacial (m,n), en el que va a determinar los pixeles dentro de la vecindad que se van a considerar en el análisis.\n",
    "\n",
    "-  Ponderación o la influencia en el cálculo de las estadísticas locales: Participa en la variable multiplicación para generar esta operación elemento por elemento de la vecindad y de esa forma también actúa en el peso de los cálculos de media y desviación local.\n",
    "Así que si se modifica los valores de selem se genera otros cálculos, en el que si fuera de 2 en el centro y 1 en el borde, entonces el código daría más relevancia al pixel central y a sus vecinos inmediatos al calcular las estadísticas.\n",
    "<p>\n",
    "3. ¿Qué efecto tiene el factor de escala de 1.5 en los píxeles mejorados y cómo podría ajustarse para obtener diferentes resultados?\n",
    "<p align=\"justify\">\n",
    "Cuando el pixel cumple con las condiciones estadísticas(media y desviación), su valor se multiplica por 1.5, lo que significa que ese pixel se vuelve más brillante, en el cual modifica sin tener que llegar a saturarlas o convertirlas en completamente blancas, pero en este caso cuando se hace un cambio a 3, trae como consecuencia que se genere un realce más fuerte y pueda ir produciendo mayor saturación o perder detalles.\n",
    "<p align=\"justify\">\n",
    "Por lo cual, si se quiere hacer un ajuste para poder comprobar y analizar los resultados, se tendría que colocar un valor menor a 1.5 si se necesita un alzamiento de brillo más natural, manteniendo cierta parte de color oscura, en caso contrario se coloca un factor mayor a 1.5, lo que provocaría que el efecto sea más drástico o si se requiere que se tenga un fuerte brillo y contraste en las partes oscuras, pero teniendo en cuenta que mayor sea ese factor originaria que se pierda toda la información del pixel o de la zona oscura.\n",
    "<p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzRmLCTHz4TI",
    "outputId": "a8e6ca52-6b1a-4b25-d815-0bc2b35e3cc8"
   },
   "outputs": [],
   "source": [
    "emma = np.uint16(cv2.imread('./lab_images/ajedrez.jpg', 0))\n",
    "emma_filtrada = filtro_espacial_estadistico(emma, selem = np.ones((5,5)))\n",
    "plt.subplots(1,2, figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(emma, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(emma_filtrada, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrRVG9pdz4TJ"
   },
   "source": [
    "### 3.- Implemente los filtros estadisticos min, max, moda y mediana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7oPykKez4TJ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def filtro_espacial_estadistico(imagen, selem = np.ones((3,3)), filter_type='median'):\n",
    "    M, N = imagen.shape\n",
    "    m, n = selem.shape\n",
    "\n",
    "    filas_add = (m - 1) // 2\n",
    "    columnas_add = (n - 1) // 2\n",
    "\n",
    "#     img_pad = np.zeros((M+ filas_adicionales*2, N + columnas_adicionales*2))\n",
    "    img_pad = np.zeros((M + m - 1, N + n - 1))\n",
    "    img_pad[filas_add: filas_add + M, columnas_add: columnas_add+ N ] = imagen\n",
    "\n",
    "    resultado = np.zeros_like(imagen)\n",
    "\n",
    "    for i in np.arange(filas_add, filas_add + M):\n",
    "        for j in np.arange(columnas_add, columnas_add + N):\n",
    "            vecindad = img_pad[i-filas_add: i+filas_add+1, j-columnas_add: j+columnas_add+1]\n",
    "\n",
    "            multiplicacion = vecindad * selem\n",
    "\n",
    "            if filter_type =='min':\n",
    "                resultado[i-filas_add, j-columnas_add] = np.min(multiplicacion)\n",
    "            elif filter_type == 'max':\n",
    "                resultado[i-filas_add, j-columnas_add] = np.max(multiplicacion)\n",
    "            elif filter_type == 'median':\n",
    "                resultado[i-filas_add, j-columnas_add] = np.median(multiplicacion)\n",
    "            elif filter_type == 'mode':\n",
    "                resultado[i-filas_add, j-columnas_add] = mode(multiplicacion, axis=None, keepdims=False).mode\n",
    "\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Qué es un filtro estadístico en el procesamiento de imágenes y cómo se aplica en el código mostrado?\n",
    "\n",
    "- Un filtro estadístico se encarga de procesar cada píxel reemplazando su valor por una estadística calculada sobre una vencidad local, como por ejemplo: mínimo, máximo, mediana o moda. Es una operación no lineal que usa información local para reducir ruido, realzar características o extraer valores.\n",
    "\n",
    "- Lo que el código hace es calcular el tamaño de vencidad mxn del selem y crea una imagen con padding de ceros de tamaño (M+m-1,N+n-1). Copia la imagen original en el centro para poder extraer vecindades centradas en todos los pixeles sin salirse de rango. Realiza una extraccion para cada posicion central que es multiplicada por el selem que por defecto en la funcion se define como una matriz de 1 de 3x3, al multiplicar el selem actua como como pondereacion o mascara. Luego realiza un calculo estadistico depende al tipo de filtro que se va a realizar, cuyo resultado se escribe en la imagen de salida en la posicion.\n",
    "\n",
    "2. ¿Qué diferencias existen entre los filtros de tipo min, max, median y mode? Explica en qué situaciones sería adecuado usar cada tipo.\n",
    "\n",
    "- Filtro tipo min:\n",
    "<p align=\"justify\">\n",
    "Este filtro se encarga de reemplazar el pixel por el valor minimo dentro de la vecindad, esto atenua zonas brillantes locales y tiende a oscurecer, ademas que elimina pequeños atributos brillantes. Es recomendado usar este filtro para poder eliminar \"pepitas\" brillantes asiladas, quitar salidas puntuales y además también es útil en la extracción de fondo en imágenes binarizadas.\n",
    "\n",
    "- Filtro tipo max:\n",
    "<p align=\"justify\">\n",
    "Este tipo de filtro se encarga de reemplazar el pixel por el valor máximo dentro de la vecindad, esto aclara zonas locales, elimina los puntos oscuros, es similar a una dialtación. Su uso es recomendado para poder eliminar \"pepitas\" oscuras aisladas, rellenar huecos pequeños y realzar píxeles brillantes dispersos. Se debe de tener cuidado en su uso porque puede expandir regiones brillantes y rellenar estructuras pequeñas.\n",
    "\n",
    "- Filtro tipo median:\n",
    "<p align=\"justify\">\n",
    "Este filtro se encarga de tomar la mediana de los valores de la vecindad, con esto se encarga de preservar los bordes mejor que un filtro promedio y de eliminar el ruido impulsivo eficazmente. Su uso es recomendado para poder quitar el ruido impulsivo, limpieza general donde no se quiere perder border, es el más usado para ruido impulsivo. Tiene una ventaja con respecto a los dos filtros anteriores porque no desplaza localmente la intensidad, sino que conserva los tonos.\n",
    "\n",
    "- Filtro tipo mode:\n",
    "<p align=\"justify\">\n",
    "Este filtro se encarga de tomar el valor que aparece con mayor frecuencia en la vecindad, esto tiende a reafirmar valores dominantes locales, lo cuál es útil en imágenes cuantizadas o con pocos niveles, además puede eliminar ruido cuando el ruido produce valores únicos y el fondo tiene un valor dominante. Es recomendado usarlo en imágenes con valores discretos o clasificaciones como mapas segmentados, imágenes binarias. Se debe de tener precaución en el uso de este filtro porque calcular la moda es más costoso computacionalmente y con imágenes con muchos valores distintos la moda puede ser poco representativa o inestable.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJdAIyA3z4TK",
    "outputId": "6ade3034-7298-42c6-86e0-2ba56d531ffe"
   },
   "outputs": [],
   "source": [
    "#MINIMO\n",
    "emma = np.uint16(cv2.imread('./lab_images/emma.jpg', 0))\n",
    "emma_filtrada = filtro_espacial_estadistico(emma,filter_type='min')\n",
    "plt.subplots(1,2, figsize=(15,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(emma, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(emma_filtrada, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htiRvTEGz4TL",
    "outputId": "dfb50a94-d69d-405b-f240-64482a99238d"
   },
   "outputs": [],
   "source": [
    "#MAX\n",
    "emma = np.uint16(cv2.imread('./lab_images/emma.jpg',0))\n",
    "emma_filtrada = filtro_espacial_estadistico(emma, filter_type='max')\n",
    "plt.subplots(1,2, figsize=(15,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(emma, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(emma_filtrada, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LiBrfzQ9z4TL",
    "outputId": "a98a39b2-a3bc-4c22-b64f-25c1e2f8eb81"
   },
   "outputs": [],
   "source": [
    "#MEDIANA\n",
    "emma = np.uint16(cv2.imread('./lab_images/ruido.png', 0))\n",
    "emma_filtrada = filtro_espacial_estadistico(emma,filter_type='median')\n",
    "plt.subplots(1,2, figsize=(15,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(emma, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(emma_filtrada, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VAIYr31z4TM",
    "outputId": "8d8a7e7f-1bdc-472a-8d7d-ceb5ea9ca52b"
   },
   "outputs": [],
   "source": [
    "#MODA\n",
    "emma = np.uint16(cv2.imread('./lab_images/ruido.png', 0))\n",
    "emma_filtrada = filtro_espacial_estadistico(emma, filter_type='mode')\n",
    "plt.subplots(1,2, figsize=(15,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(emma, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(emma_filtrada, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jj4l7KKOz4TM"
   },
   "source": [
    "### 4.- Implemente los filtros espaciales de suavizado y nitidez explicados en clase\n",
    "\n",
    "Utilizando la funcion **convolve2d(img, kernel, mode= \"same\")** de **scipy.signal** y los kernels: \n",
    "(tambien se puede usar **correlate2d**)\n",
    "* Promedio\n",
    "* Gaussiano\n",
    "* Laplaciano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2O8yB7sz4TN",
    "outputId": "72b2ca44-36f8-4abc-97f8-51d6fdbf3832"
   },
   "outputs": [],
   "source": [
    "#PROMEDIO\n",
    "from scipy import signal\n",
    "\n",
    "img = cv2.imread(\"./lab_images/scarlett_oc.png\", 0)/255\n",
    "kernel = np.ones((11,11))/121\n",
    "\n",
    "out = signal.convolve2d(img, kernel, mode= \"same\")\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(out), cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PElWFyorz4TN",
    "outputId": "a40db10e-36e9-4b02-cfca-edbe5ed8fd44"
   },
   "outputs": [],
   "source": [
    "#GAUSSIANO\n",
    "from scipy import signal\n",
    "\n",
    "img = cv2.imread(\"./lab_images/scarlett_oc.png\", 0)/255\n",
    "# kernel = np.array([[1,2,1], [2,4,2], [1,2,1]])/16\n",
    "kernel = np.array([1,4,7,4,1])*np.array([[1],[4],[7],[4],[1]])\n",
    "kernel = kernel/np.sum(kernel)\n",
    "\n",
    "out = signal.convolve2d(img, kernel, mode= \"same\")\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.abs(out), cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-P1skiqz4TN",
    "outputId": "1abd7a31-98f7-4589-ae09-9e86ba0cb5fe"
   },
   "outputs": [],
   "source": [
    "#LAPLACIANO\n",
    "from scipy import signal\n",
    "A = 1.5\n",
    "img = cv2.imread(\"./lab_images/scarlett_oc.png\", 0)/255\n",
    "kernel = np.array([[-1,-1,-1], [-1,A+8,-1], [-1,-1,-1]])\n",
    "\n",
    "out = signal.convolve2d(img, kernel, mode= \"same\")\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(out, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5mHgwoHIz4TO"
   },
   "source": [
    "**Utilizando OpenCV:**\n",
    "* cv2.blur(img, (Tamaño_kernel))\n",
    "* cv2.GaussianBlur(img,(Tamaño_kernel),desviacion_estandar)\n",
    "* cv2.medianBlur(img,Tamaño_kernel)\n",
    "* cv2.bilateralFilter(img,tamaño_kernel,sigmacolor,sigmaspace)  [Mas info](https://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MANDUCHI1/Bilateral_Filtering.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEpuV8Mbz4TO",
    "outputId": "96c1bdc8-62cc-467e-dfa8-2775390885ea"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./lab_images/scarlett_oc.png\")[..., ::-1]\n",
    "\n",
    "out = cv2.blur(img, (7,7))\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(out, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR9_VbyCz4TP",
    "outputId": "2cf386a7-7f78-46d3-9e9d-f63f504fdd78"
   },
   "outputs": [],
   "source": [
    "out = cv2.GaussianBlur(img,(7,7), 2)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(out, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8_Lq_Erz4TP",
    "outputId": "2f48890f-3d2e-4f34-b735-fc0d882ec236"
   },
   "outputs": [],
   "source": [
    "img_joker = cv2.imread('./lab_images/ruido.png')[..., ::-1]\n",
    "\n",
    "img_joker_filtrada = cv2.medianBlur(img_joker, 7)\n",
    "\n",
    "plt.subplots(1,2, figsize=(15,20))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img_joker, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img_joker_filtrada, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhJR6yzaz4TP",
    "outputId": "cadd46fd-d1e6-4b2a-dec6-b2b089f27be3"
   },
   "outputs": [],
   "source": [
    "out = cv2.bilateralFilter(img,7, 160, 160)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(121)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(out, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Cuál es la diferencia fundamental entre los filtros de suavizado (como el de promedio y el Gaussiano) y los filtros de nitidez (como el Laplaciano)?\n",
    "<p align=\"justify\">\n",
    "- La principal diferencia es el objetivo que tiene cada uno de estos filtros, el de suavizado se encarga de eliminar detalla de alta frecuencia y producir una imagen más \"suave\" mientras que el filtro de nitidez tiende a realzar cambios locales en la intensidad, aumentando la percepción de detalle y contraste local. Otras diferencias son que el suavizado atenúa las frecuencias altas, reduce el ruido y su kernel está normalizado para mantener el nivel promedio de la imagen mientras que la nitidez realza o pasa las frecuencias altas, atenúa las frecuencias bajas y su kernel tiene suma igual a 0, por lo que detecta cambios sin aportar componente de baja frecuencia.\n",
    "<p>\n",
    "\n",
    "2. ¿Cuáles son las principales diferencias en los resultados obtenidos al aplicar un filtro de promedio versus un filtro Gaussiano?\n",
    "\n",
    "- Peso del kernel: El filtro promedio tiene todos los coeficientes iguales y el píxel de salida es la media aritmética de la vecindad, mientras que el gaussiano, son pesos centrados mayores y decrecen suavemente haica afuera, donde el centro tiene más influencia.\n",
    "- Respuesta de frecuencia: El promedio tiene una respuesta tipo sinc con oscilaciones mientras que la gaussiana tiene atenuación suave y monótona en frecuencias.\n",
    "- Efecto visual: El filtro promedio tiene un blureo fuerte y homogéneo; suaviza texturas uniformemente, puede produci bordes más difusos y pérdida de contraste local, mientras que el gaussiano suaviza pero preserva mejor la estructura local, aplica una transición más natural.\n",
    "3. ¿Qué propiedades tiene el kernel Laplaciano y cómo contribuye a la nitidez de la imagen? ¿Qué efectos visuales produce al aplicarse a una imagen?\n",
    "- El kernel Laplaciano es un filtro de segunda derivada que mida la curvatura local de la intensidad, detecta cambios rápidos en intensidad en todas las direcciones, donde la forma típica es una matriz de 3x3 donde el centro es el 8 y su alrededor es el -1. Las propiedades matemática es que es isotrópico en la práctica, la suma de sus coeficientes es cero por eso actúa como filtro pasa-altas y resalta regiones con alta segunda derivada.\n",
    "- Este filtro contribuye a la nitidex de la imagen, extrayendo las componentes de alta frecuencia, donde si se suma una versión escalada del mapa Laplaciano  la imagen original obtienes un realce de bordes, esto incrementa el contraste local en los bordes que genera una percepción con mayor nitidez.\n",
    "- El efecto visual que produce es tener bordes más marcados, con contornos y texturas más visibles, aumenta la percepción de detalle en regiones con transiciones de intensidad. Lo negativo es que amplifica el ruido, crea halos alrededor de bordes si la ganacia es alta y produce un exceso de contraste en texturas finas si se aplica sin suavizar antes.\n",
    "4. ¿Qué significa el argumento mode=\"same\" en la función convolve2d y cómo afecta el tamaño de la imagen resultante después de aplicar el filtro?\n",
    "- El modo same de dice a convolve2d que devuelva una salida del mismo tamaño que la imagen de entrada, internamente la convolución se calcula centrando el kernel sobre cada píxel de la imagen de entrada, para bordes toma en cuanta cómo se rellenan los valores fuera del límite.\n",
    "- EL tamaño de la imagen resultante es el mismo que el de la imagen de entrada, mientras que los valores cercanos al vorde dependen del manejo de fronteras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tB-QsGdjz4TP"
   },
   "source": [
    "### 5.- Implemente un algoritmo para muestre el uso de la mascara de desenfoque (unsharp mask) y el filtro de altoaumento (Highboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2Wmf9Lzz4TP",
    "outputId": "5d6d7c8c-4b4b-4f4c-d828-ce3f873ce51e"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./lab_images/scarlett_oc.png\")[..., ::-1]/255\n",
    "\n",
    "blur = cv2.blur(img, (7,7))\n",
    "\n",
    "mask = img - blur\n",
    "\n",
    "unsharp_image = mask + img\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(131)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.subplot(132)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.subplot(133)\n",
    "plt.imshow(unsharp_image, cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Cómo funciona la máscara de desenfoque (unsharp mask) para realzar los detalles de una imagen, y cuál es el papel del filtro de suavizado en este proceso?\n",
    "---\n",
    "\n",
    "La **máscara de desenfoque (Unsharp Mask)** realza detalles tomando la parte de alta frecuencia de una imagen.  \n",
    "Primero se aplica un **suavizado (blur)** para obtener una versión sin bordes. Luego se calcula la **máscara** como la diferencia:\n",
    "\n",
    "mask = Imag - I_blur\n",
    "\n",
    "Esta máscara contiene los detalles y bordes. Después se suman esos detalles a la imagen original:\n",
    "\n",
    "I_unsharp = Imag + mask\n",
    "\n",
    "El **filtro de suavizado** es fundamental porque determina qué tanto detalle se elimina (bajas frecuencias) y, por lo tanto, qué tanto detalle se realza al volver a sumarlo.Tipificado en el codigo :\n",
    "\n",
    "{blur = cv2.blur(img, (7, 7))}\n",
    "En resumen este asignación aplica un filtro de suavizado (low-pass filter) con un kernel de 7×7, donde esto produce una imagen desenfocada, sin detalles ni bordes.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "2.  ¿En qué se diferencia el filtro de alto aumento (Highboost) de la máscara de desenfoque estándar, y cómo se puede ajustar el factor de amplificación (boosting factor) para controlar el nivel de realce en la imagen?\n",
    "---\n",
    "\n",
    "El **filtro de alto aumento (Highboost)** es una versión generalizada de la máscara de desenfoque estándar.  \n",
    "En la máscara de desenfoque tradicional, el realce se obtiene sumando la máscara de detalles una sola vez:\n",
    "\n",
    "unsharp = Imag + (Imag - I_blur)\n",
    "\n",
    "En el filtro Highboost, se añade un **factor de amplificación A (>1)** que permite aumentar la contribución de los detalles:\n",
    "\n",
    "highboost = Imag + A * (Imag - I_blur)\n",
    "\n",
    "La diferencia principal es que en **unsharp mask A = 1**, mientras que en **Highboost A > 1**, lo cual incrementa la intensidad del realce.  \n",
    "Al aumentar el valor de A, los bordes y texturas se vuelven más visibles:  \n",
    "- A cercano a 1 produce un realce suave.  \n",
    "- A entre 1.5 y 3 genera mayor nitidez y contraste en los detalles.\n",
    "\n",
    "Por lo tanto, el **boosting factor A** controla directamente el nivel de realce aplicado a la imagen.\n",
    "Asi como se muestra en la siguiente compilación de codigo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"./lab_images/scarlett_oc.png\")[..., ::-1]/255\n",
    "\n",
    "blur = cv2.blur(img, (7,7))\n",
    "\n",
    "mask = img - blur\n",
    "\n",
    "unsharp_image = mask + img\n",
    "\n",
    "# Highboost (A > 1)\n",
    "A = 5 \n",
    "highboost = img + A * mask\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.title(\"Imagen Original\")\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.title(\"Máscara (Detalles)\")\n",
    "plt.imshow(mask )  \n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.title(\"Unsharp Mask por defecto donde (A=1)\")\n",
    "plt.imshow(unsharp_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.title(\"Highboost (A=5)\")\n",
    "plt.imshow(highboost)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyXejkPwz4TQ"
   },
   "source": [
    "### 6.- Implemente un algoritmo para mostrar la gradiente de una imagen\n",
    "**Use las mascaras:**\n",
    "* Roberts\n",
    "* Prewit\n",
    "* Sobel\n",
    "* Scharr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgPHMF0ez4TQ",
    "outputId": "90065ff1-9ed2-48fd-a5ad-9155780598ba"
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "img = cv2.imread(\"./lab_images/frutas.jpg\", 0) / 255.0\n",
    "\n",
    "# Máscaras Roberts\n",
    "kernelh = np.array([[0, -1],\n",
    "                    [1,  0]])\n",
    "\n",
    "kernelv = np.array([[-1, 0],\n",
    "                    [ 0, 1]])\n",
    "# Convolución\n",
    "outh = signal.convolve2d(img, kernelh, mode=\"same\")\n",
    "outv = signal.convolve2d(img, kernelv, mode=\"same\")\n",
    "# Combinación\n",
    "outf = outh + outv\n",
    "\n",
    "# Mostrar resultados\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(221)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Imagen Original\")\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(outh * 5, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.title(\"Gradiente Horizontal (Roberts Gx)\")\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(outv * 5, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.title(\"Gradiente Vertical (Roberts Gy)\")\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.imshow(outf + img, cmap=\"gray\", vmin=0, vmax=1)\n",
    "plt.title(\"Bordes Combinados (Roberts)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels Prewitt\n",
    "kernelh = np.array([[-1, -1, -1],\n",
    "                    [ 0,  0,  0],\n",
    "                    [ 1,  1,  1]])\n",
    "\n",
    "kernelv = np.array([[-1, 0, 1],\n",
    "                    [-1, 0, 1],\n",
    "                    [-1, 0, 1]])\n",
    "\n",
    "Gx = signal.convolve2d(img, kernelh, mode=\"same\")\n",
    "Gy = signal.convolve2d(img, kernelv, mode=\"same\")\n",
    "G  = np.sqrt(Gx**2 + Gy**2)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Imagen Original\")\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(Gx, cmap=\"gray\")\n",
    "plt.title(\"Prewitt Gx\")\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(Gy, cmap=\"gray\")\n",
    "plt.title(\"Prewitt Gy\")\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.imshow(G, cmap=\"gray\")\n",
    "plt.title(\"Magnitud del Gradiente (Prewitt)\")\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.imshow(img + G, cmap=\"gray\")\n",
    "plt.title(\"Imagen + Gradiente (Prewitt)\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels Sobel\n",
    "kernelh = np.array([[-1, -2, -1],\n",
    "                    [ 0,  0,  0],\n",
    "                    [ 1,  2,  1]])\n",
    "\n",
    "kernelv = np.array([[-1, 0, 1],\n",
    "                    [-2, 0, 2],\n",
    "                    [-1, 0, 1]])\n",
    "\n",
    "Gx = signal.convolve2d(img, kernelh, mode=\"same\")\n",
    "Gy = signal.convolve2d(img, kernelv, mode=\"same\")\n",
    "G  = np.sqrt(Gx**2 + Gy**2)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Imagen Original\")\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(Gx, cmap=\"gray\")\n",
    "plt.title(\"Sobel Gx\")\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(Gy, cmap=\"gray\")\n",
    "plt.title(\"Sobel Gy\")\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.imshow(G, cmap=\"gray\")\n",
    "plt.title(\"Magnitud del Gradiente (Sobel)\")\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.imshow(img + G, cmap=\"gray\")\n",
    "plt.title(\"Imagen + Gradiente (Sobel)\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels Scharr\n",
    "kernelh = np.array([[-3, -10, -3],\n",
    "                    [ 0,   0,  0],\n",
    "                    [ 3,  10,  3]])\n",
    "\n",
    "kernelv = np.array([[-3,  0,  3],\n",
    "                    [-10, 0, 10],\n",
    "                    [-3,  0,  3]])\n",
    "\n",
    "Gx = signal.convolve2d(img, kernelh, mode=\"same\")\n",
    "Gy = signal.convolve2d(img, kernelv, mode=\"same\")\n",
    "G  = np.sqrt(Gx**2 + Gy**2)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.title(\"Imagen Original\")\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.imshow(Gx, cmap=\"gray\")\n",
    "plt.title(\"Scharr Gx\")\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.imshow(Gy, cmap=\"gray\")\n",
    "plt.title(\"Scharr Gy\")\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.imshow(G, cmap=\"gray\")\n",
    "plt.title(\"Magnitud del Gradiente (Scharr)\")\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.imshow(img + G, cmap=\"gray\")\n",
    "plt.title(\"Imagen + Gradiente (Scharr)\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de implementar las mascaras de gradientes\n",
    "\n",
    "### 1. ¿Cuál es la característica distintiva de la máscara de Roberts y por qué es menos precisa?\n",
    "\n",
    "La máscara de **Roberts** se distingue porque calcula el gradiente usando **kernels muy pequeños de 2×2**, y detecta bordes principalmente en **diagonales**.  \n",
    "Debido a este tamaño reducido, captura variaciones muy locales y se vuelve **más sensible al ruido** y **menos precisa en imágenes con gradientes suaves o detalles complejos**.  \n",
    "Su simplicidad lo hace rápido, pero menos robusto que operadores de 3×3 como Prewitt, Sobel o Scharr.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. ¿Cómo afectan Sobel y Scharr a la precisión en la detección de bordes y cuándo se elige cada uno?\n",
    "\n",
    "Las máscaras de **Sobel** y **Scharr** usan kernels de 3×3 que suavizan en la dirección perpendicular al borde, lo que mejora la **estabilidad** y reduce el **ruido**.  \n",
    "Sobel aplica pesos moderados en la dirección del gradiente, mientras que **Scharr** utiliza coeficientes optimizados que producen una estimación más **precisa y rotacionalmente simétrica** del gradiente.\n",
    "\n",
    "- **Sobel** se prefiere cuando se busca un detector estable, económico y suficientemente preciso.  \n",
    "- **Scharr** se elige cuando se requiere **mayor exactitud**, especialmente en aplicaciones que necesitan gradientes más fieles (visión por computadora, mediciones, análisis fino de contornos).\n",
    "\n",
    "En resumen, **Scharr ofrece mayor precisión**, pero Sobel es más ligero computacionalmente.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Practica 07A - Procesamiento de imagenes en el dominio del espacio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
